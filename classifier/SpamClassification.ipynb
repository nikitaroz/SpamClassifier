{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/34478398/import-local-function-from-a-module-housed-in-another-directory-with-relative-im\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from common.utils import get_data_urls, fetch_data, get_labeled_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_urls = get_data_urls()\n",
    "#fetch_data(data_urls)\n",
    "\n",
    "data_files, class_labels = get_labeled_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training set size is\t 7479\nTest set size is\t 1870\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_files, test_files, y_train, y_test = train_test_split(data_files, class_labels,\n",
    "                                                            test_size=0.2, random_state=44)\n",
    "print(f\"Training set size is\\t {len(train_files)}\")\n",
    "print(f\"Test set size is\\t {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "More than one match found for (?:with(?! cipher)\\s+(?P<with>.+?)(?:\\s*[(]?envelope-from|\\s*[(]?envelope-sender|\\s+from|\\s+by|\\s+id|\\s+for|\\s+via|;)) in from unknown HELO mfrenchw2k mfrench42@62.254.163.42 with login by smtp.mail.vip.sc5.yahoo.com with SMTP; 13 Aug 2002 09:18:55 -0000\n",
      "More than one match found for (?:with(?! cipher)\\s+(?P<with>.+?)(?:\\s*[(]?envelope-from|\\s*[(]?envelope-sender|\\s+from|\\s+by|\\s+id|\\s+for|\\s+via|;)) in from unknown HELO mfrenchw2k mfrench42@62.254.163.42 with login by smtp.mail.vip.sc5.yahoo.com with SMTP; 13 Aug 2002 09:18:55 -0000\n",
      "More than one match found for (?:(?:^|\\s)from\\s+(?P<from>.+?)(?:\\s*[(]?envelope-from|\\s*[(]?envelope-sender|\\s+by|\\s+with(?! cipher)|\\s+id|\\s+for|\\s+via|;)) in from chekitb5876.com 195.27.92.154 by asptown.co.kr 211.52.47.8 with Nmail V3.1 20010905 S for <jm@netnoteinc.com> from <jimmiester@hanmesoft.co.kr>; Sun, 02 Jun 2002 02:37:30 +0900\n",
      "More than one match found for (?:(?:^|\\s)from\\s+(?P<from>.+?)(?:\\s*[(]?envelope-from|\\s*[(]?envelope-sender|\\s+by|\\s+with(?! cipher)|\\s+id|\\s+for|\\s+via|;)) in from chekitb5876.com 195.27.92.154 by asptown.co.kr 211.52.47.8 with Nmail V3.1 20010905 S for <jm@netnoteinc.com> from <jimmiester@hanmesoft.co.kr>; Sun, 02 Jun 2002 02:37:30 +0900\n"
     ]
    }
   ],
   "source": [
    "from mailparser import mailparser\n",
    "from common.message import Message\n",
    "\n",
    "messages = []\n",
    "for i, message in enumerate(train_files[:100]):\n",
    "    m = Message(mailparser.parse_from_file(message), y_train[i])\n",
    "    m._extract_body_features()\n",
    "    messages.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_prefix_regex, compile_infix_regex, compile_suffix_regex\n",
    "\n",
    "def custom_tokenizer(nlp):\n",
    "    infixes = nlp.Defaults.infixes + tuple([r\"\\b[\\[\\(]\\b\"]) \n",
    "    infix_re = compile_infix_regex(infixes)\n",
    "    prefix_re = compile_prefix_regex(nlp.Defaults.prefixes)\n",
    "    suffix_re = compile_suffix_regex(nlp.Defaults.suffixes)\n",
    "    return Tokenizer(\n",
    "        nlp.vocab,\n",
    "        prefix_search=prefix_re.search,\n",
    "        suffix_search=suffix_re.search,\n",
    "        infix_finditer=infix_re.finditer,\n",
    "        token_match=None\n",
    "    )\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\", \"ner\", \"textcat\"])\n",
    "nlp.tokenizer = custom_tokenizer(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.database_populator import DatabasePopulator\n",
    "\n",
    "db_populator = DatabasePopulator(\"../db/spam.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"../db/spam.db\")\n",
    "cursor = conn.cursor()\n",
    "conn.executescript(open(\"../schema.sql\").read())\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_populator.populate_message_table(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.message import Message\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "class MessageTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, input=\"filename\"):\n",
    "        '''string {‘filename’, ‘file’, ‘content’}, '''\n",
    "        self.input = input\n",
    "        self.messages = []\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        '''X is a list of files'''\n",
    "        feature_aggregator = []\n",
    "        if isinstance(X, str):\n",
    "             raise ValueError(\"Must be a list or iterable, not a string\")\n",
    "        for x in X:\n",
    "            if self.input == \"content\":\n",
    "                mailparser_obj = mailparser.parse_from_string(x)\n",
    "            elif self.input == \"file\":\n",
    "                mailparser_obj = mailparser.parse_from_file_obj(x)\n",
    "            elif self.input == \"filename\":\n",
    "                mailparser_obj = mailparser.parse_from_file(x)\n",
    "            \n",
    "            feature_aggregator.append(Message(mailparser_obj, None).extract_features())\n",
    "            \n",
    "        return pd.DataFrame.from_records(feature_aggregator)\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"message_trf\", MessageTransformer()),\n",
    "    (\"vectorizer\", \n",
    "         ColumnTransformer([\n",
    "            (\"tdidf_body_vectorizer\", TfidfVectorizer(max_features=1000), \"body_tokens\"),\n",
    "         ])\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "More than one match found for (?:with(?! cipher)\\s+(?P<with>.+?)(?:\\s*[(]?envelope-from|\\s*[(]?envelope-sender|\\s+from|\\s+by|\\s+id|\\s+for|\\s+via|;)) in from unknown HELO mfrenchw2k mfrench42@62.254.163.42 with login by smtp.mail.vip.sc5.yahoo.com with SMTP; 13 Aug 2002 09:18:55 -0000\n",
      "More than one match found for (?:with(?! cipher)\\s+(?P<with>.+?)(?:\\s*[(]?envelope-from|\\s*[(]?envelope-sender|\\s+from|\\s+by|\\s+id|\\s+for|\\s+via|;)) in from unknown HELO mfrenchw2k mfrench42@62.254.163.42 with login by smtp.mail.vip.sc5.yahoo.com with SMTP; 13 Aug 2002 09:18:55 -0000\n",
      "More than one match found for (?:(?:^|\\s)from\\s+(?P<from>.+?)(?:\\s*[(]?envelope-from|\\s*[(]?envelope-sender|\\s+by|\\s+with(?! cipher)|\\s+id|\\s+for|\\s+via|;)) in from chekitb5876.com 195.27.92.154 by asptown.co.kr 211.52.47.8 with Nmail V3.1 20010905 S for <jm@netnoteinc.com> from <jimmiester@hanmesoft.co.kr>; Sun, 02 Jun 2002 02:37:30 +0900\n",
      "More than one match found for (?:(?:^|\\s)from\\s+(?P<from>.+?)(?:\\s*[(]?envelope-from|\\s*[(]?envelope-sender|\\s+by|\\s+with(?! cipher)|\\s+id|\\s+for|\\s+via|;)) in from chekitb5876.com 195.27.92.154 by asptown.co.kr 211.52.47.8 with Nmail V3.1 20010905 S for <jm@netnoteinc.com> from <jimmiester@hanmesoft.co.kr>; Sun, 02 Jun 2002 02:37:30 +0900\n"
     ]
    }
   ],
   "source": [
    "test = pipeline.fit_transform(train_files[:100], y_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#xgb.XGBClassifier()\n",
    "xgb_clf = xgb.XGBClassifier(booster=\"gblinear\").fit(test, y_train[:100])\n",
    "#naive_clf = MultinomialNB().fit(test, y_train[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pipeline[\"vectorizer\"].named_transformers_[\"tdidf_body_vectorizer\"]\n",
    "p.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = []\n",
    "for i in zip(p.get_feature_names(), xgb_clf.coef_):\n",
    "    coefficients.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "len(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "OperationalError",
     "evalue": "near \"coefficient\": syntax error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-3c5117a76ad1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../db/spam.db\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecutemany\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"INSERT INTO feature(feature coefficient) values (?, ?)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoefficients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: near \"coefficient\": syntax error"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"../db/spam.db\")\n",
    "cursor = conn.cursor()\n",
    "cursor.executemany(\"INSERT INTO feature(feature coefficient) values (?, ?)\", coefficients)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "xgb_train_accuracy = np.mean(cross_val_score(xgb_clf, test, y_train[:400], cv=5))\n",
    "naive_train_accuracy = np.mean(cross_val_score(naive_clf, test, y_train[:400], cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7483"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Accuracy:\t 0.9199999999999999\n",
      "Naive Bayes Accuracy:\t 0.9349999999999999\n"
     ]
    }
   ],
   "source": [
    "print(\"XGB Accuracy:\\t\", xgb_train_accuracy)\n",
    "print(\"Naive Bayes Accuracy:\\t\", naive_train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(vectorizer, \"vectorizer.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}