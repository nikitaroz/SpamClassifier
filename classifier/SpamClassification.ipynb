{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/34478398/import-local-function-from-a-module-housed-in-another-directory-with-relative-im\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from common.utils import get_data_urls, fetch_data, get_labeled_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_urls = get_data_urls()\n",
    "#fetch_data(data_urls)\n",
    "\n",
    "data_files, class_labels = get_labeled_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training set size is\t 7479\nTest set size is\t 1870\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_files, test_files, y_train, y_test = train_test_split(data_files, class_labels,\n",
    "                                                            test_size=0.2, random_state=44)\n",
    "print(f\"Training set size is\\t {len(train_files)}\")\n",
    "print(f\"Test set size is\\t {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.message import Message\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import mailparser\n",
    "\n",
    "class MessageTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, input=\"message\"):\n",
    "        '''string {‘filename’, ‘file’, ‘content’}, '''\n",
    "        self.input = input\n",
    "        self.messages = []\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        '''X is a list of files'''\n",
    "        feature_aggregator = []\n",
    "        if isinstance(X, str):\n",
    "             raise ValueError(\"Must be a list or iterable, not a string\")\n",
    "        for x in X:\n",
    "            if self.input == \"content\":\n",
    "                mailparser_obj = mailparser.parse_from_string(x)\n",
    "            elif self.input == \"file\":\n",
    "                mailparser_obj = mailparser.parse_from_file_obj(x)\n",
    "            elif self.input == \"filename\":\n",
    "                mailparser_obj = mailparser.parse_from_file(x)\n",
    "            elif self.input == \"message\":\n",
    "                feature_aggregator.append(x.extract_features())\n",
    "                continue\n",
    "            feature_aggregator.append(Message(mailparser_obj).extract_features())\n",
    "\n",
    "            \n",
    "        return pd.DataFrame.from_records(feature_aggregator)\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"message_trf\", MessageTransformer()),\n",
    "    (\"vectorizer\", \n",
    "         ColumnTransformer([\n",
    "            (\"tdidf_body_vectorizer\", TfidfVectorizer(max_features=5000), \"body_tokens\"),\n",
    "         ])\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Email content 'ms-tnef' not handled\n",
      "Email content 'pgp-signature' not handled\n",
      "Email content 'pgp-signature' not handled\n"
     ]
    }
   ],
   "source": [
    "from mailparser import mailparser\n",
    "from common.message import Message\n",
    "\n",
    "N = 100\n",
    "\n",
    "messages = []\n",
    "for i, message in enumerate(train_files[:N]):\n",
    "    try:\n",
    "        m = Message(mailparser.parse_from_file(message))\n",
    "    except OSError:\n",
    "        m = Message(mailparser.parse_from_string(\" \"))\n",
    "    messages.append(m)\n",
    "\n",
    "labels = y_train[:N]\n",
    "\n",
    "features = pipeline.fit_transform(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBClassifier(base_score=None, booster='gblinear',\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             param_grid={'alpha': (0.0, 0.1, 1.0, 5.0),\n",
       "                         'lambda': (0.0, 0.1, 1.0, 5.0)})"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    \"lambda\": (0.0, 0.1, 1.0, 5.0),\n",
    "    \"alpha\": (0.0, 0.1, 1.0, 5.0),\n",
    "}\n",
    "xgb_clf = xgb.XGBClassifier(booster=\"gblinear\")\n",
    "clf = GridSearchCV(xgb_clf, parameters)\n",
    "clf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = clf.best_estimator_\n",
    "coefs = classifier.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: unify pipeline and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.database_populator import DatabasePopulator\n",
    "\n",
    "db_populator = DatabasePopulator(\"../db/spam.db\")\n",
    "db_populator.populate_schema(\"../schema.sql\")\n",
    "db_populator.populate_message_table(messages, y_train[:N])\n",
    "\n",
    "vectorizer = pipeline[\"vectorizer\"].named_transformers_[\"tdidf_body_vectorizer\"]\n",
    "coefficients = []\n",
    "for i in zip(vectorizer.get_feature_names(), coefs):\n",
    "    coefficients.append(i)\n",
    "\n",
    "db_populator.populate_feature_table(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "XGB Accuracy:\t 0.93\nDummy Accuracy\t 0.616\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier().fit(messages, y_train[:N])\n",
    "dummy_train_accuracy = np.mean(cross_val_score(dummy_clf, features, y_train[:N], cv=5))\n",
    "xgb_train_accuracy = np.mean(cross_val_score(classifier, features, y_train[:N], cv=5))\n",
    "print(\"XGB Accuracy:\\t\", xgb_train_accuracy)\n",
    "print(\"Dummy Accuracy\\t\", dummy_train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(vectorizer, \"vectorizer.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}